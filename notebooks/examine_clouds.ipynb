{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Point Clouds\n",
    "\n",
    "This notebook is for examining the point cloud data generated by the first analysis phase (phase 1). Plots of the individual traces point clouds in two and three dimensions can be made to check the status of the results. This is helpful for testing the parameters generated by the first phase. It actually runs a mini-version of phase 1. Note that the data generated here is NOT saved. This is only for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "First we import all of the necessary code from the repository. Note the sys.path.append. This is used to pass the path to the repository to the interpreter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from pcutils.core.config import load_config\n",
    "from pcutils.core.workspace import Workspace\n",
    "from pcutils.core.get_event import GetEvent, GET_DATA_TRACE_START, GET_DATA_TRACE_STOP\n",
    "from pcutils.core.point_cloud import PointCloud\n",
    "from pcutils.phase_1 import get_event_range\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "Now we'll load the configuration we want to use. Configurations are stored in JSON files using the conventions defined by the example file shipped with the repository (config.json). By default, this notebook reads the example file, but this can be changed. Additionally, once the config is loaded, you can always tweak the fields for rapid testing of different parameters.\n",
    "\n",
    "We then hand off the workspace configuration to the Workspace class. The Workspace helps us handle paths to various files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('../local_config.json')\n",
    "# Tweak some parameters\n",
    "# config.trace.peak_threshold = 1\n",
    "\n",
    "# Create our workspace\n",
    "ws = Workspace(config.workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "Now that our configuration is loaded, we can start reading and analyzing some data. Step one is to access the raw trace datafile. This means that you need to pick a run to analyze; we store the run number in a variable for later reference. To analyze a different run simply change the run number.\n",
    "\n",
    "We then ask the workspace to retrieve the trace file path for our selected run number. We then use the h5py library to open the associated h5 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = config.run.run_min\n",
    "trace_file = h5.File(ws.get_trace_file_path(run_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our file is now loaded. Now we need to navigate to the correct group of the h5 structure. The traces are stored in the 'get' group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_group: h5.Group = trace_file['get']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a group loaded, we can now access the actual trace data! The default loading behavior is to select a random event (set of traces), since when testing you'll want to test your parameters on many different events. However, one can also fix the event by setting the event number to a constant value for debugging. Once the event number is chosen we then retrieve the raw trace data from the h5 file as a Dataset. Note that this operation can fail sometimes, if an event was omitted for some reason. If that happens just select a different event number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the trace file for the range of events\n",
    "min_event, max_event = get_event_range(trace_file)\n",
    "# Select a random event\n",
    "event_number = random.randint(min_event, max_event)\n",
    "# Can always overwrite with hardcoded event number if needed\n",
    "event_number = 362\n",
    "\n",
    "event_data: h5.Dataset = trace_group[f'evt{event_number}_data']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing\n",
    "\n",
    "Now that we've loaded our data, it's time to do some analysis! Step one is just to see what some traces look like, without any analysis at all. Again here, we're going to pick a random trace to look at, but you may want to pick a specific trace depending on your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_number = random.randint(0, len(event_data))\n",
    "raw_trace_data = event_data[trace_number]\n",
    "time_bucket_range = np.arange(start=0, stop=512)\n",
    "plt.plot(time_bucket_range, raw_trace_data[GET_DATA_TRACE_START:GET_DATA_TRACE_STOP])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you should see the plot of the raw trace! Now we can feed this trace data through the initial analysis by passing it along to the GetEvent class, along with the event number, and trace configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = GetEvent(event_data, event_number, config.trace)\n",
    "plt.cla()\n",
    "plt.plot(time_bucket_range, event.traces[trace_number].raw_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see a pretty different trace on the other side of the initial analysis! The big thing that happened in that little code snippet was the removal of the trace baseline. This is done via a low-pass filter using a Fourier transform.\n",
    "\n",
    "The next step is to run the peak finding analysis and generate a point cloud by retrieveing the positional data of each trace. This is done by passing our GetEvent to the PointCloud class, along with some additional data for connecting the electronics hardware address to the physical detector pad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = PointCloud()\n",
    "cloud.load_cloud_from_get_event(event, ws.get_pad_map())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our cloud is loaded, the first thing we'd want to check is the peak finding. To retrieve the z-position of each trace, the peak (centroid) of each trace must be found. We can examine this using the code snippet below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time_bucket_range, event.traces[trace_number].raw_data)\n",
    "for peak in event.traces[trace_number].peaks:\n",
    "    plt.scatter(peak.centroid, peak.amplitude, color='red')\n",
    "    plt.scatter(peak.negative_inflection, event.traces[trace_number].raw_data[peak.negative_inflection], color='green')\n",
    "    plt.scatter(peak.positive_inflection, event.traces[trace_number].raw_data[peak.positive_inflection], color='green')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see your trace plotted again, but this time with highlighted points corresponding to the centroid (red) and the peak edges (green). If you don't see anything, try tweaking some configuration parameters and re-running everything!\n",
    "\n",
    "Now that we've looked at the peak finding, we can look at the actual point cloud itself! Below are several plots examining the geometry of the point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the 3-D point cloud\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(cloud.cloud[:, 2], cloud.cloud[:, 0], cloud.cloud[:, 1], s=3)\n",
    "ax.set_title('Point Cloud 3D')\n",
    "ax.set_xlabel('z(mm)')\n",
    "ax.set_xlim(0.0, 1000.0)\n",
    "ax.set_ylabel('x(mm)')\n",
    "ax.set_ylim(-300.0, 300.0)\n",
    "ax.set_zlabel('y(mm)')\n",
    "ax.set_zlim(-300.0, 300.0)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot x-y  projection\n",
    "plt.scatter(cloud.cloud[:, 0], cloud.cloud[:, 1], s=3)\n",
    "plt.title('Point Cloud x-y Projection')\n",
    "plt.xlabel('x(mm)')\n",
    "plt.xlim(-300.0, 300.0)\n",
    "plt.ylabel('y(mm)')\n",
    "plt.ylim(-300.0, 300.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot z-x projection\n",
    "plt.scatter(cloud.cloud[:, 2], cloud.cloud[:, 0], s=3)\n",
    "plt.title('Point Cloud z-x Projection')\n",
    "plt.xlabel('z(mm)')\n",
    "plt.xlim(0.0, 1000.0)\n",
    "plt.ylabel('x(mm)')\n",
    "plt.ylim(-300.0, 300.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot z-y projection\n",
    "plt.scatter(cloud.cloud[:, 2], cloud.cloud[:, 1], s=3)\n",
    "plt.title('Point Cloud z-y Projection')\n",
    "plt.xlabel('z(mm)')\n",
    "plt.xlim(0.0, 1000.0)\n",
    "plt.ylabel('y(mm)')\n",
    "plt.ylim(-300.0, 300.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even plot some interesting physics! Below is an example intended to try and plot a Bragg curve from the point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot r-Charge projection\n",
    "plt.scatter(np.linalg.norm(cloud.cloud[:, :3], axis=1), cloud.cloud[:, 4], s=3)\n",
    "plt.title('Point Cloud R-Integrated Charge')\n",
    "plt.xlabel('R(mm)')\n",
    "plt.ylabel('Integrated Charge (unitless)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "That is a basic analysis of the traces and the point cloud data! With well tuned parameters, you're now ready to run the phase 1 analysis. Follow the instructions in the README to do this. Once thats done, you can move on to the next stage, generating and identifying clusters within the point clouds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
