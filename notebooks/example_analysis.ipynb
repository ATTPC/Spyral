{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Example Physics Analysis\n",
    "\n",
    "This notebook is an example of what post-Spyral analysis might look like. To use this notebook all four phases of Spyral *must* have been run on the data. After all of the phases are run on a dataset, it is time to do some actual physics analysis! In general physics analysis is highly specific to the experiment being run, but this notebook aims to give a little overview on what an analysis might look like if one wants to use some of the tools given by the application. \n",
    "\n",
    "First we import our modules we need. We'll also define a helpful constant, which we'll use to convert $B\\rho$ to momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from spyral.core.config import load_config\n",
    "from spyral.core.workspace import Workspace\n",
    "from spyral.core.constants import AMU_2_MEV, QBRHO_2_P\n",
    "\n",
    "from spyral_utils.nuclear import NuclearDataMap\n",
    "from spyral_utils.nuclear.target import GasTarget, load_target\n",
    "from spyral_utils.plot import Histogrammer\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load our configuration. The configuration will help us define the target material (the active target) which we'll use for some energy loss analysis. We'll also use the nuclear data map to get the masses for the reactants we're interested in. This example loads the data for the reaction $^{16}\\mathrm{C}\\left(\\mathrm{d}, \\mathrm{d}\\right){}^{16}\\mathrm{C}$ in inverse kinematics (where $^{16}\\mathrm{C}$ is the beam projectile). We also define the projectile starting energy, that is the energy from the accelerator after passing through the window foils of the AT-TPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('../local_config.json')\n",
    "ws = Workspace(config.workspace)\n",
    "nuclear_map = NuclearDataMap()\n",
    "target_material = load_target(Path(config.solver.gas_data_path), nuclear_map)\n",
    "if not isinstance(target_material, GasTarget):\n",
    "    print('Target error!')\n",
    "ejectile = nuclear_map.get_data(1, 2)\n",
    "projectile = nuclear_map.get_data(6, 16)\n",
    "target = nuclear_map.get_data(1, 2)\n",
    "residual = nuclear_map.get_data(6, 16)\n",
    "mass_amu = projectile.mass / AMU_2_MEV\n",
    "proj_energy_start = 11.3 * mass_amu #MeV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a histogramming system. The Histogrammer class wraps the numpy histogramming functionality. This is useful because we'll probably want to look at several runs, and neither numpy or matplotlib provide clean native functionality for this. We'll define a couple of histograms that will plot some useful data for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grammer = Histogrammer()\n",
    "grammer.add_hist2d('ke_theta', (360, 1600), ((0.0, 180.0), (0.0, 80.0)))\n",
    "grammer.add_hist2d('ke_phi', (360, 1600), ((0.0, 360.0), (0.0, 80.0)))\n",
    "grammer.add_hist1d('ex', 250, (-5.0, 10.0))\n",
    "grammer.add_hist1d('chisq', 1000, (0.0, 1.0e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll do some data analysis! Here we're going to calculate the ejectile (detected) particle kinetic energy from our fitted $B\\rho$ and then combine that with the projectile kinetic energy, polar reaction angle, and masses to calculate the excitation energy of the residual nucleus. Note that we use the vertex position to calculate the distance travelled for the beam in the gas and then calculate the energy lost by the beam travelling to the reaction vertex. This data is then given to the histogrammer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_vec = np.array([0., 0., 0., target.mass])\n",
    "Q_mass = target.mass + projectile.mass - ejectile.mass - residual.mass\n",
    "kinetics = np.empty(0, float)\n",
    "angles = np.empty(0, float)\n",
    "chisq = np.empty(0, float)\n",
    "for run in range(config.run.run_min, config.run.run_max+1):\n",
    "    df = None\n",
    "    try:\n",
    "        df = pl.read_parquet(ws.get_physics_file_path_parquet(run, ejectile))\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "\n",
    "    df = df.filter((pl.col('redchisq') < 1.0e-4) & (pl.col(\"vertex_z\") > 0.005) & (pl.col(\"vertex_z\") < 0.995))\n",
    "\n",
    "    vertices = df.select(['vertex_x', 'vertex_y', 'vertex_z']).to_numpy()\n",
    "    distances = np.linalg.norm(vertices, axis=1)\n",
    "    proj_energy = proj_energy_start - target_material.get_energy_loss(projectile, proj_energy_start, distances)\n",
    "\n",
    "    brho = df.select('brho').to_numpy().flatten()\n",
    "    momentum = df.select('brho').to_numpy().flatten() * float(ejectile.Z) * QBRHO_2_P\n",
    "    kinetic_energy = np.sqrt(momentum**2.0 + ejectile.mass**2.0) - ejectile.mass\n",
    "    polar = df.select('polar').to_numpy().flatten()\n",
    "    az = df.select('azimuthal').to_numpy().flatten()\n",
    "    cs = df.select('redchisq').to_numpy().flatten()\n",
    "\n",
    "    qterm = 2.0/residual.mass * np.sqrt(projectile.mass * ejectile.mass * kinetic_energy * proj_energy) * np.cos(polar)\n",
    "    Q_rxn = -1.0 * (kinetic_energy * (1.0 + ejectile.mass/residual.mass) + proj_energy * ( projectile.mass/residual.mass - 1.0) - qterm)\n",
    "\n",
    "    grammer.fill_hist2d('ke_theta', np.rad2deg(polar), kinetic_energy)\n",
    "    grammer.fill_hist2d('ke_theta_resid', np.rad2deg(polar), kinetic_energy)\n",
    "    grammer.fill_hist2d('ke_phi', np.rad2deg(az), kinetic_energy)\n",
    "    grammer.fill_hist1d('ex', Q_rxn + Q_mass)\n",
    "    grammer.fill_hist1d(\"chisq\", cs)\n",
    "    kinetics = np.append(kinetics, kinetic_energy)\n",
    "    angles = np.append(angles, np.rad2deg(polar))\n",
    "    chisq = np.append(chisq, cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the kinematics to the expected values. Here we'll calculate the ejectile kinetic energy for a range of reaction angles. Note that in this case we cannot account for the exact beam energy after travelling through the gas without doing a form of Monte-Carlo simulation. By default we only calculate the ground state of the resiudal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_range = np.linspace(0., np.pi, 1000)\n",
    "\n",
    "ex = 0.0\n",
    "\n",
    "Q = projectile.mass + target.mass - (ejectile.mass + residual.mass + ex)\n",
    "term1 = np.sqrt(projectile.mass * ejectile.mass * proj_energy_start) / (ejectile.mass + residual.mass) * np.cos(angle_range)\n",
    "term2 = (proj_energy_start * (residual.mass - projectile.mass) + residual.mass*Q) / (residual.mass + ejectile.mass)\n",
    "eject_energy = term1 + np.sqrt(term1*term1 + term2)\n",
    "eject_energy = eject_energy**2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets make some plots! These first ones will be the energy-angle relationship for the ejectile (detected) particle. The interesting one is energy vs. polar ($\\theta$). On this histogram we also plot our calculated energy angle relationship. Here we're looking for general agreement with the trend, not exact values. Because the calculation doesn't have a good way to handle the beam energy loss, the data will always look a little more \"smeared\" than the calculation would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ke_theta = grammer.get_hist2d(\"ke_theta\")\n",
    "ke_phi = grammer.get_hist2d(\"ke_phi\")\n",
    "fig, ax = plt.subplots(1,2)\n",
    "mesh = ax[0].pcolormesh(ke_theta.x_bins, ke_theta.y_bins, ke_theta.counts, norm=\"log\")\n",
    "ax[0].set_title(\"Kinetic Energy vs. Polar Angle\")\n",
    "ax[0].set_xlabel(r\"$\\theta$ (deg)\")\n",
    "ax[0].set_ylabel(\"Kinetic Energy (MeV)\")\n",
    "fig.colorbar(mesh, ax=ax[0])\n",
    "ax[0].plot(np.rad2deg(angle_range), eject_energy)\n",
    "mesh = ax[1].pcolormesh(ke_phi.x_bins, ke_phi.y_bins, ke_phi.counts)\n",
    "ax[1].set_title(\"Kinetic Energy vs. Azimuthal Angle\")\n",
    "ax[1].set_xlabel(r\"$\\phi$ (deg)\")\n",
    "ax[1].set_ylabel(\"Kinetic Energy (MeV)\")\n",
    "fig.colorbar(mesh, ax=ax[1])\n",
    "fig.set_figheight(8.0)\n",
    "fig.set_figwidth(11.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also plot our calculated residual excitation energy. In many ways this is the primary plot of interest, as it should show you the states in the residual that were populated in the reaction with their relative intensities (uncorrected for detector efficiency of course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_hist = grammer.get_hist1d(\"ex\")\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.stairs(ex_hist.counts, edges=ex_hist.bins)\n",
    "ax.set_title(f\"{residual.get_latex_rep()} Spectrum\")\n",
    "ax.set_xlabel(\"Excitation Energy (MeV)\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "fig.set_figwidth(8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data you see doesn't match your expectations, there probably was an issue with one of the earlier analysis phases or the configuration parameters. Try  tweaking some the configuration parameters and see what it does to the final results! Below is also a plot of the error (chisquare) for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = grammer.get_hist1d(\"chisq\")\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.stairs(hist.counts, edges=hist.bins)\n",
    "ax.set_title(f\"{residual.get_latex_rep()} Error\")\n",
    "ax.set_xlabel(\"Error\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "fig.set_figwidth(8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, below we demonstrate how to fit your excitation energy spectrum and extract some state parameters. This *will not* work by default, it was tuned to a random dataset. But it will demonstrate how to use lmfit to fit your spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmfit\n",
    "\n",
    "hist = grammer.get_hist1d(\"ex\")\n",
    "\n",
    "peak1 = lmfit.models.GaussianModel(prefix=\"peak1_\")\n",
    "peak1_bins, peak1_counts = hist.get_subrange((-0.5, 0.5))\n",
    "peak1_bins += 0.5 * hist.bin_width\n",
    "peak1_weights = 1.0/np.sqrt(peak1_counts)\n",
    "peak1_weights[peak1_counts == 0.0] = 1.0\n",
    "pars = peak1.guess(x=peak1_bins, data=peak1_counts, weights=peak1_weights)\n",
    "\n",
    "# peak2 = lmfit.models.LorentzianModel(prefix=\"peak2_\")\n",
    "# peak2_bins, peak2_counts = hist.get_subrange((0.0, 1.0))\n",
    "# peak2_bins += 0.5 * hist.bin_width\n",
    "# peak2_weights = 1.0/np.sqrt(peak2_counts)\n",
    "# peak2_weights[peak2_counts == 0.0] = 1.0\n",
    "# pars.update(peak2.guess(x=peak2_bins, data=peak2_counts, weights=peak2_weights))\n",
    "\n",
    "# peak3 = lmfit.models.LorentzianModel(prefix=\"peak3_\")\n",
    "# peak3_bins, peak3_counts = hist.get_subrange((2.0, 3.0))\n",
    "# peak3_bins += 0.5 * hist.bin_width\n",
    "# peak3_weights = 1.0/np.sqrt(peak3_counts)\n",
    "# peak3_weights[peak3_counts == 0.0] = 1.0\n",
    "# pars.update(peak3.guess(x=peak3_bins, data=peak3_counts, weights=peak3_weights))\n",
    "\n",
    "# peak4 = lmfit.models.LorentzianModel(prefix=\"peak4_\")\n",
    "# peak4_bins, peak4_counts = hist.get_subrange((3.0, 5.0))\n",
    "# peak4_bins += 0.5 * hist.bin_width\n",
    "# peak4_weights = 1.0/np.sqrt(peak4_counts)\n",
    "# peak4_weights[peak4_counts == 0.0] = 1.0\n",
    "# pars.update(peak4.guess(x=peak4_bins, data=peak4_counts, weights=peak4_weights))\n",
    "\n",
    "# peak5 = lmfit.models.LorentzianModel(prefix=\"peak5_\")\n",
    "# peak5_bins, peak5_counts = hist.get_subrange((5.0, 6.5))\n",
    "# peak5_bins += 0.5 * hist.bin_width\n",
    "# peak5_weights = 1.0/np.sqrt(peak5_counts)\n",
    "# peak5_weights[peak5_counts == 0.0] = 1.0\n",
    "# pars.update(peak5.guess(x=peak5_bins, data=peak5_counts, weights=peak5_weights))\n",
    "\n",
    "bkgnd = lmfit.models.LinearModel(prefix=\"bkgnd_\")\n",
    "bkgnd_bins, bkgnd_counts = hist.get_subrange((-2.0, -1.0))\n",
    "bkgnd_bins += 0.5 * hist.bin_width\n",
    "bkgnd_weights = 1.0/np.sqrt(bkgnd_counts)\n",
    "bkgnd_weights[bkgnd_counts == 0.0] = 1.0\n",
    "pars.update(bkgnd.guess(x=bkgnd_bins, data=bkgnd_counts))\n",
    "pars[\"bkgnd_slope\"].min = 0.0\n",
    "\n",
    "# total_fit = peak1 + peak2 + peak3 + peak4 + peak5 + bkgnd\n",
    "total_fit = peak1 + bkgnd\n",
    "total_bins, total_counts = hist.get_subrange((-1.0, 1.0))\n",
    "total_bins += 0.5 * hist.bin_width\n",
    "total_weights = 1.0/np.sqrt(total_counts)\n",
    "total_weights[total_counts == 0.0] = 1.0\n",
    "total_result = total_fit.fit(params=pars, x=total_bins, data=total_counts, weights=total_weights)\n",
    "comps = total_result.eval_components(x=total_bins)\n",
    "total_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.stairs(hist.counts, edges=hist.bins, label=\"Spectrum\")\n",
    "ax.plot(total_bins, total_result.best_fit, label=\"Total Fit\")\n",
    "ax.plot(total_bins, comps[\"peak1_\"], label=\"peak1\")\n",
    "# ax.plot(total_bins, comps[\"peak2_\"], label=\"peak2\")\n",
    "# ax.plot(total_bins, comps[\"peak3_\"], label=\"peak3\")\n",
    "# ax.plot(total_bins, comps[\"peak4_\"], label=\"peak4\")\n",
    "# ax.plot(total_bins, comps[\"peak5_\"], label=\"peak5\")\n",
    "ax.plot(total_bins, comps[\"bkgnd_\"], label=\"bkgnd\")\n",
    "ax.set_title(f\"{residual.get_latex_rep()} Spectrum Fit\")\n",
    "ax.set_xlabel(\"Excitation Energy (MeV)\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "fig.set_figwidth(8.0)\n",
    "fig.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
