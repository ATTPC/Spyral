{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Physics Using the Interpolation Method\n",
    "\n",
    "Now that we have generated our clusters and estimated the physical observables of interest we are ready to initiate the solving phase of the analysis, where we attempt to extract the exact physics observables by fitting solutions of the equations of motion to the data. There are several approaches to solving in this application, and this notebook looks at what is referred to as the interpolation method. The interpolation method works by pre-generating a bunch of solutions to the ODE's and then interpolation on these solutions to try and fit the data. It has the advantage of being very fast; the ODE's only ever need to be solved once, and then all the remaining calculation is just simple (bi)linear interpolation.\n",
    "\n",
    "First let's take care of all of our imports.\n",
    "\n",
    "Note: this notebook assumes you've already done the work of generating the interpolation scheme. This is done by simply running phase 4 in the main application with an interpolation scheme defined. This can take some time (20-30 min depending on the coarse-ness of the grid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from pcutils.core.track_generator import create_interpolator\n",
    "from pcutils.core.config import load_config\n",
    "from pcutils.core.workspace import Workspace\n",
    "from pcutils.core.particle_id import load_particle_id\n",
    "from pcutils.core.target import Target\n",
    "from pcutils.core.solver_interp import fit_model, Guess, generate_trajectory\n",
    "from pcutils.core.cluster import Cluster\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with all of our code imported we will setup the configuration, loading our config file and creating all of our data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('../local_config.json')\n",
    "ws = Workspace(config.workspace)\n",
    "track_path = ws.get_track_file(config.solver.interp_file_name)\n",
    "tracks = create_interpolator(track_path)\n",
    "nuc_map = ws.get_nuclear_map()\n",
    "pid = load_particle_id(ws.get_gate_file_path(config.solver.particle_id_filename), nuc_map)\n",
    "target = Target(config.solver.gas_data_path, nuc_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll pick a data file (the min run number defined in the config by default) and load up the associated physics estimates. By default we select a random row in the estimates (a random cluster/trajectory) but you can always set the row to a hardcoded number to do some testing of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = config.run.run_min\n",
    "cluster_file = h5.File(ws.get_cluster_file_path(run_number))\n",
    "estimate_df = pl.scan_parquet(ws.get_estimate_file_path_parquet(run_number))\n",
    "estimate_gated = estimate_df.filter(pl.struct(['dEdx', 'brho']).map(pid.cut.is_cols_inside)).collect().to_dict()\n",
    "cluster_group = cluster_file['cluster']\n",
    "nrows = len(estimate_gated['event'])\n",
    "row = np.random.randint(0, nrows)\n",
    "# row = 48\n",
    "print(f'row: {row}')\n",
    "event = estimate_gated['event'][row]\n",
    "cluster_index = estimate_gated['cluster_index'][row]\n",
    "print(f'event: {event}')\n",
    "print(f'cluster index: {cluster_index}')\n",
    "event_group = cluster_group[f'event_{event}']\n",
    "local_cluster = event_group[f'cluster_{cluster_index}']\n",
    "print(f'Direction: {estimate_gated[\"direction\"][row]}')\n",
    "cluster = Cluster(event, local_cluster.attrs['label'], local_cluster['cloud'][:].copy())\n",
    "cluster.z_bin_width = local_cluster.attrs['z_bin_width']\n",
    "cluster.z_bin_low_edge = local_cluster.attrs['z_bin_low_edge']\n",
    "cluster.z_bin_hi_edge = local_cluster.attrs['z_bin_hi_edge']\n",
    "cluster.n_z_bins = local_cluster.attrs['n_z_bins']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our cluster and estimated observables loaded, we are ready to fit to the data. We setup our Guess object from our estimates and then pass that along to the fit_model function. Sometimes this will return None when a given trajectory has estimates that are outside the interpolation table (these typically correspond to bad events). If this happens a error will occur. Simply re-run the notebook until the a good event is randomly selected. Note that the first time you run this block it might take a couple of seconds. This is because the interpolation method uses a just-in-time compiler (jit) to speed up the calculations. The first time you call the code, the code gets compiled (resulting in a slowdown). But everytime the code is called after that, the compiled program is used, resulting in enormus performance gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = Guess(estimate_gated['brho'][row], estimate_gated['polar'][row], estimate_gated['azimuthal'][row], estimate_gated['vertex_x'][row], estimate_gated['vertex_y'][row], estimate_gated['vertex_z'][row])\n",
    "print(guess)\n",
    "result = fit_model(cluster, guess, tracks, pid.nucleus)\n",
    "if result is None:\n",
    "    print('Guess outside of interpolation range!')\n",
    "best_fit_trajectory_xy = generate_trajectory(result, tracks, pid.nucleus).interpolate(cluster.data[:, 2]*0.001)\n",
    "cluster.data[:, :3] *= 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a good event was chosen, you should see above a print out of the fit results. Key values are the chi-square (which should be small) and the variable values, which are the fitted observables. Also important are the correlations, which tell you if any of the parameters are co-dependent. If two parameters have a correlation of 1.0 they are basically degenerate to the fitter, which is very bad.\n",
    "\n",
    "We can also plot the results of the fit against the data to vizualize the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(cluster.data[:, 0], cluster.data[:, 1], s=3, label='data')\n",
    "plt.scatter(best_fit_trajectory_xy[:, 0], best_fit_trajectory_xy[:, 1], s=3, label='fit')\n",
    "plt.xlabel(\"x (mm)\")\n",
    "plt.ylabel(\"y (mm)\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(cluster.data[:, 2], cluster.data[:, 1], s=3, label='data')\n",
    "plt.scatter(cluster.data[:, 2], best_fit_trajectory_xy[:, 1], s=3, label='fit')\n",
    "plt.xlabel(\"z (mm)\")\n",
    "plt.ylabel(\"y (mm)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(cluster.data[:, 2], cluster.data[:, 0], s=3, label='data')\n",
    "plt.scatter(cluster.data[:, 2], best_fit_trajectory_xy[:, 0], s=3, label='fit')\n",
    "plt.xlabel(\"z (mm)\")\n",
    "plt.ylabel(\"x (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you see a nice fit to the data! If the fit looks bad, there are several things to check. First is the particle ID gate; if the wrong particle group is selected, the fit will fail spectacularly. Another is the coarse-ness of the interpolation scheme. If there are too few bins in the polar angle or the particle kinetic energy, the interpolation may not generate good values. Finally, it is also good to make sure that the target gas is correctly defined with the right pressure and chemistry."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
