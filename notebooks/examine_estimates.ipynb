{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Physics Parameters\n",
    "\n",
    "This notebook shows how the estimation phase of Spyral works. To use this notebook the first two phases (point cloud and cluster) of Spyral *must* have been run on the data. Once clusters have been identified, the next step is to estimate the physics parameters which will be feed to the solver of choice (either ODE or Kalman filter). The main points are the initial orientation and energy of the particle, as well as the species of the particle. \n",
    "\n",
    "First we import our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from spyral.core.config import load_config\n",
    "from spyral.core.workspace import Workspace\n",
    "from spyral.core.clusterize import Cluster\n",
    "from spyral.core.estimator import estimate_physics\n",
    "from spyral.geometry.circle import generate_circle_points\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our modules, we need to load our configuration and workspace, as usual. Here we also load up a result container that we will use with our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('../local_config.json')\n",
    "ws = Workspace(config.workspace)\n",
    "\n",
    "results: dict[str, list] = {'event': [], 'cluster_index': [], 'cluster_label': [], 'ic_amplitude': [], 'ic_centroid': [], 'ic_integral': [], 'vertex_x': [], 'vertex_y': [], 'vertex_z': [],\\\n",
    "                             'center_x': [], 'center_y': [], 'center_z': [], 'polar': [], 'azimuthal': [],\\\n",
    "                             'brho': [], 'dEdx': [], 'dE': [], 'arclength': [], 'direction': [], 'eloss': [], 'cutoff_index': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our workspace we can then request the file for our clusters, and read in a random cluster from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = config.run.run_min\n",
    "cluster_file = h5.File(ws.get_cluster_file_path(run_number))\n",
    "cluster_group = cluster_file['cluster']\n",
    "min_event = cluster_group.attrs['min_event']\n",
    "max_event = cluster_group.attrs['max_event']\n",
    "event_group = None\n",
    "event = 0\n",
    "nclusters = 0\n",
    "while(True):\n",
    "    event = np.random.randint(min_event, max_event)\n",
    "    # event = 438\n",
    "    try:\n",
    "        event_group = cluster_group[f'event_{event}']\n",
    "        nclusters = event_group.attrs['nclusters']\n",
    "        if nclusters != 0:\n",
    "            break\n",
    "    except:\n",
    "        continue\n",
    "local_cluster = None\n",
    "cluster_index = np.random.randint(0, nclusters)\n",
    "# cluster_index = 0\n",
    "local_cluster = event_group[f'cluster_{cluster_index}']\n",
    "\n",
    "print(f'event: {event}')\n",
    "print(f'cluster index: {cluster_index}')\n",
    "cluster = Cluster(event, local_cluster.attrs['label'], local_cluster['cloud'][:].copy())\n",
    "print(f\"cluster size: {len(cluster.data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our cluster selected and loaded, we can now send it, along with some configuration paramters, through the estimator code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_physics(\n",
    "    cluster_index, \n",
    "    cluster, \n",
    "    event_group.attrs['ic_amplitude'], \n",
    "    event_group.attrs['ic_centroid'], \n",
    "    event_group.attrs['ic_integral'], \n",
    "    config.estimate, \n",
    "    config.detector, \n",
    "    results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at some of our results! First we'll look at the circle fit, and the estimated vertex poistion, which is how we estimate $B\\rho$. We'll also draw a line corresponding to the estimated initial direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results[\"event\"]) == 0:\n",
    "    raise Exception(\"No results\")\n",
    "\n",
    "center_x = results['center_x'][-1]\n",
    "center_y = results['center_y'][-1]\n",
    "vertex_x = results['vertex_x'][-1]\n",
    "vertex_y = results['vertex_y'][-1]\n",
    "vertex_z = results['vertex_z'][-1]\n",
    "theta = results['polar'][-1]\n",
    "phi = results['azimuthal'][-1]\n",
    "brho = results['brho'][-1]\n",
    "cutoff_index = results['cutoff_index'][-1]\n",
    "rho_mm = brho/config.detector.magnetic_field * 1000.0 * np.sin(theta)\n",
    "print(f\"Brho(T*m): {brho}\")\n",
    "print(f\"Rho(mm): {rho_mm}\")\n",
    "print(f\"Polar(deg):{theta * 180.0/np.pi}\")\n",
    "print(f\"Direction: {results['direction'][-1]}\")\n",
    "print(f\"Vertex z: {vertex_z} Cluster z start: {cluster.data[0, 2]}\")\n",
    "length_samples = np.linspace(1.0, 50.0, 50)\n",
    "dir_x_samples = length_samples * np.cos(phi) + vertex_x\n",
    "dir_y_samples = length_samples * np.sin(phi) + vertex_y\n",
    "\n",
    "circle_points = generate_circle_points(center_x, center_y, rho_mm)\n",
    "beam_region = generate_circle_points(0., 0., config.detector.beam_region_radius)\n",
    "\n",
    "fig = make_subplots(2,1,specs=[[{\"type\": \"scene\"}],[{\"type\": \"xy\"}]],row_heights=[0.25,0.75])\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=cluster.data[:, 2], \n",
    "        y=cluster.data[:, 0], \n",
    "        z=cluster.data[:, 1], \n",
    "        mode=\"markers\",\n",
    "        marker= {\n",
    "            \"size\": 3,\n",
    "            \"color\": cluster.data[:, 3]\n",
    "        }, \n",
    "        name=f\"Cluster-3D\"\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=[cluster.data[0, 2]], \n",
    "        y=[cluster.data[0, 0]], \n",
    "        z=[cluster.data[0, 1]], \n",
    "        mode=\"markers\",\n",
    "        marker= {\n",
    "            \"size\": 3,\n",
    "            \"color\": \"red\"\n",
    "        }, \n",
    "        name=f\"Cluster-3D Start\"\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=[vertex_z], \n",
    "        y=[vertex_x], \n",
    "        z=[vertex_y], \n",
    "        mode=\"markers\",\n",
    "        marker= {\n",
    "            \"size\": 3,\n",
    "            \"color\": \"green\"\n",
    "        }, \n",
    "        name=f\"Vertex-3D\"\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=cluster.data[:, 0], y=cluster.data[:, 1], mode=\"markers\", marker={\"color\": cluster.data[:, 3]}, name=\"Cluster\"),\n",
    "    row=2,\n",
    "    col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[cluster.data[0, 0]], y=[cluster.data[0, 1]], mode=\"markers\", marker={\"color\": \"red\"}, name=\"Cluster Start\"),\n",
    "    row=2,\n",
    "    col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=circle_points[:, 0], y=circle_points[:, 1], mode=\"lines\", name=\"Circle Fit\"),\n",
    "    row=2,\n",
    "    col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=beam_region[:, 0], y=beam_region[:, 1], mode=\"lines\", name=\"Beam Region\"),\n",
    "    row=2,\n",
    "    col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[vertex_x], y=[vertex_y], mode=\"markers\", marker={\"color\": \"green\"}, name=\"Vertex\"),\n",
    "    row=2,\n",
    "    col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[cluster.data[cutoff_index-1, 0]], y=[cluster.data[cutoff_index-1, 1]], mode=\"markers\", marker={\"color\": \"aqua\"}, name=\"Cutoff\"),\n",
    "    row=2,\n",
    "    col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=dir_x_samples, y=dir_y_samples, mode=\"lines\", name=\"Initial Direction\"),\n",
    "    row=2,\n",
    "    col=1\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"X (mm)\",\n",
    "    yaxis_title=\"Y (mm)\",\n",
    "    xaxis_range=[-300.0,300.0],\n",
    "    yaxis_range=[-300.0,300.0],\n",
    "    scene = {\n",
    "        # \"xaxis_range\": [0.0, 1000.0],\n",
    "        \"yaxis_range\": [-300.0, 300.0],\n",
    "        \"zaxis_range\": [-300.0, 300.0],\n",
    "        \"xaxis_title\": \"Z (mm)\",\n",
    "        \"yaxis_title\": \"X (mm)\",\n",
    "        \"zaxis_title\": \"Y (mm)\",\n",
    "        \"aspectratio\": {\n",
    "            \"x\": 3.3,\n",
    "            \"y\": 1.0,\n",
    "            \"z\": 1.0\n",
    "        }\n",
    "    },\n",
    "    width=900,\n",
    "    height=1200\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also start building up a particle id using $B\\rho$ and $\\frac{dE}{dx}$. If you run the three cells above this repeatedly, you'll see the plot below fill with data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=results[\"dEdx\"], y=results[\"brho\"], mode=\"markers\", name=\"PID\")\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"dEdx\",\n",
    "    yaxis_title=\"B&#961;\",\n",
    "    xaxis_range=[0.0, 5.0e3],\n",
    "    yaxis_range=[0.0, 3.0]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way you can examine and tune the parameters for the estimation phase. If you want to make complete particle ID plots, it is recommended to use the plotter.py script rather than these notebooks, which are more for demonstration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
